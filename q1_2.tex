
\section*{שאלה {1}}
כצעד ראשון, התבקשנו לחלק את הנתונים לנתוני אימון 
\ToEn{train-set} כאשר
\ToEn{60\%} מהתמונות ישמשו לאימון, \ToEn{20\%} לוולידציה ו- \ToEn{20\%} לבדיקה.
\medskip
\subsection*{חלוקה של הדאטה למחיצות}
החלוקה נעשתה תוך שימוש בפונקציית \ToEn{train\_test\_split} מהספרייה, הקוד נמצא בקובץ \ToEn{split\_train.py}.\newline
לאחר יצירת רשימת כל הקבצים, נעשית הגרלת חלוקה לשלוש המחיצות
\ToEn{Train, Validation, Test}
לפי ההסתברויות שהתבקשנו. לאחר מכן הקבצים מופנים ל-3 ספריות בשמות המתאימים.

\subsection*{שיטת העבודה}
ניתן לחלק את ה-\ToEn{pipeline} לכמה שלבים, שכל אחד מהם קורא פלט מדיסק, מעבד אותו, ושומר לדיסק את השלב הבא.
\newline
כך ניתן לפתח כל שלב בנפרד ולחזור אחורה בלי להתחיל בכל פעם מההתחלה.

השלבים הם:
\begin{enumerate}[start=0]
\item חלוקה של הדאטה (תמונות) למחיצות
\item הפעלה של \ToEn{Feature Extraction} על כל התמונות ושמירת הפיצ'רים בלבד
\item פעולת קוונטיזציה (\ToEn{Vector Quantization})  - אימון \ToEn{K-Means} על מרחב הפיצ'רים שהתקבל בשלב הקודם ושמירת המודל. מספר המרכזים שבחרתי בשלב זה הוא 128.
\item שלב תרגום ע"י \ToEn{Bag Of Features} - לכל תמונה המאופיינת כעת ע"י סט פיצ'רים, חישוב האשכול \ToEn{(Cluster)} שאליו שייך כל פיצ'ר. כעת הייצוג של התמונה הופך להיות היסטוגרמה - לכל אשכול k מהו מספר המאפיינים ששייך לו.\newline
הייצוג הזה של תמונה כהיסטוגרמה נשמר לדיסק.
\item אימון מסווג אשר מקבל כקלט בשלב האימון זוגות של היסטוגרמה+מחלקה , ולומד לסווג היסטוגרמה למחלקה
\item הפעלת המסווג על מחיצות \ToEn{test, validation} וחישוב המטריקות המתאימות להערכת הביצועים
\end{enumerate}
\par
נשים לב כי ה-\ToEn{pipeline} הזה זהה לגמרי בין שאלות 1,2 - ההבדל העיקרי הוא איזה אלגוריתם מבצע את פעולת \ToEn{Feature Extraction}.\par
בשאלה מס' 1 השתמשתי באלגוריתם \ToEn{Orb}, אשר מחזיר פיצ'רים בגודל 32 - במספר שאינו ידוע מראש אך חסום.\newline
בשאלה 2 השתמשתי בשכבות הראשונות של רשת נוירונים מסוג \ToEn{VGG16} ללא השכבות האחרונות שלה - המוצא של שכבות אלה הוא 64 פיצ'רים בגודל 512, שכל אחד מהם מתאים לסביבה של ריבוע אחד בתמונה המקורית ומתאר אותו ואת סביבתו (ברשת קלאסית בגודל \ToEn{64x64} כל סביבה כזאת היא פיקסל).

\subsection*{נקודות חשובות בפתרון של שני הסעיפים האלה}
\begin{itemize}
    \item מספר הפיצ'רים שמחזירה רשת הנוירונים הוא קבוע. אבל מספר הפיצ'רים שמוחזרים ע"י אלגוריתם כגון \ToEn{Orb} יכול להיות קטן יותר או גדול יותר מהמספר שהחלטנו לקבוע (כאן בחרנו לקבוע קבוצה בגודל 500).\newline
    במקרה זה יש לחתוך או להשלים את הפיצ'רים למספר קבוע, כיוון שהיישום הבסיסי של היסטוגרמה כזו מניח מספר קבוע (וסכום ערכי ההיסטוגרמה יהיה שווה למספר הזה). \newline
    לכן חייבים לבצע התאמה למספר קבוע של פיצ'רים.
    \begin{itemize}
    \item  
אם המספר קטן מדי, משלימים את הקבוצה באמצעות אפסים (כלומר פיצ'רים שערך כולם הם אפס).
\item אם המספר גדול מדי, ממיינים את הפיצ'רים לפי ערך ה- \ToEn{Response} ושומרים רק את בעלי הערכים הגבוהים עד לגודל הקבוצה הרצוי.
\item ערך זה מייצג "איכות" או "בטחון" של האלגוריתם בנקודת המפתח שהתגלתה. הנקודות שבהן ערך זה גבוה הן הבולטות יותר. לכן הגיוני להשתמש בנקודות שיש להן ערך תגובה גבוה (עד למספר הנדרש) ולהתעלם מן האחרות.
\item אם אכן יהיו הרבה "השלמות" של פיצ'רים ריקים (ערך 0) בסט האימון, סביר להניח שלפחות אחד מהאשכולות שיחושב באלגוריתם \ToEn{k-means} יהיה קרוב מאד אל הנקודה של ראשית הצירים, כשאליה ימופו כל הקואורדינטות הריקות הנ"ל.
    \end{itemize}
\item המידע הטבלאי נשמר באמצעות \ToEn{Pandas DataFrame} בפורמט \ToEn{feather} המאופיין ביעילות קריאה גבוהה. 
\item המידע הבינארי, כגון סריאליזציה של מודלים, נשמר בפורמט \ToEn{pickle}.
\item לצורך בניית המסווג בשלב הסופי, ניסיתי מספר אפשרויות.
    \begin{itemize}
        \item שתי וריאציות של מסווג \ToEn{AdaBoostClassifier}
        \item שתי וריאציות של מסווג \ToEn{XGBClassifier}
    \end{itemize}
\end{itemize}

\subsection*{הרצת השאלה}
לצורך הרצת פתרון השאלה יש להריץ את הפקודה:
\EN
\begin{framed}
\begin{verbatim}
cd src
python mmn12_q1.py
\end{verbatim}
\end{framed}
\HE
במצב ברירת המחדל ללא פרמטרים, ההרצה תתחיל משלב 1 כפי שמפורט ב"שיטת העבודה".
לחילופין ניתן להריץ החל משלב מתקדם יותר, למשל:
\EN
\begin{framed}
\begin{verbatim}
python mmn12_q1.py --stage=3
\end{verbatim}
\end{framed}
\HE

\section*{שאלות שנשאלנו}
מה הפרמטרים האופטימליים של המסווג?\newline
יש להציג את הביצועים ע"י עקומות 
\ToEn{ROC}, חישוב ה-\ToEn{AUC} וגם \ToEn{confusion matrix} ו- \ToEn{precision-recall} 
\section*{תשובות לשאלות}
הטבלה:
\HE
על-פי מדד ה-\ToEn{AUC}, נראה שהמסווג המוצלח ביותר עבור \ToEn{Orb} הוא \ToEn{ADABOOST2}. הפרמטרים שבהם השתמשתי עבורו הם:
\EN
\begin{lstlisting}
'ADABOOST2':
AdaBoostClassifier(
    estimator=DecisionTreeClassifier(max_depth=2), 
    n_estimators=20,  # Number of boosting rounds
    learning_rate=0.2,  # Learning rate
    random_state=42  # Seed for reproducibility
)
\end{lstlisting}
\CreateCustomTable{ביצועי המסווגים השונים}{data/results_extractor_Orb.csv}
%\clearpage

\HE
\newpage
והגרפים המתאימים עבור מחיצת ה-\ToEn{Test} הם:

\CreateFigure{images/roc_curve_global_Orb_ADABOOST2_test.png}{עקום \ToEn{ROC}}
\CreateFigure{images/prc_curve_global_Orb_ADABOOST2_test.png}{עקום \ToEn{Precision-Recall}}
\CreateFigure{images/confusion_matrix_Orb_ADABOOST2_test.png}{מטריצת הבלבול}
\clearpage
\newpage
\HE
\section*{שאלה {2}}
בשאלה 2 השתמשתי באותו ה- \ToEn{pipeline} , עם הבדלים מעטים בלבד: שימוש בטנזורים (התוצר שיוצא מתוך הרשת), מימדים שונים במעט, וכו'.

גם כאן בשלב האחרון בדקתי את אותם מסווגים ואלה התוצאות שלהם:
\CreateCustomTable{ביצועי המסווגים השונים}{data/results_extractor_VGG.csv}

כל ארבעת המסווגים הגיעו לתוצאות דומות, אם כי כאן המוצלח ביותר היה \ToEn{XGB2} , אשר הפרמטרים שלו הם:
\EN
\begin{lstlisting}
'XGB2': 
XGBClassifier(
    objective='multi:softmax',  # Multiclass classification
    num_class=8,  # Number of classes
    max_depth=3,  # Tree depth
    learning_rate=0.03,  # Learning rate (eta)
    n_estimators=10,  # Number of trees
    random_state=42  # Seed for reproducibility
),
\end{lstlisting}
\HE
\newpage
ואילו הגרפים שמתאימים לתוצאות שלו הם:

\CreateFigure{images/roc_curve_global_VGG_XGB2_test.png}{עקום \ToEn{ROC}}
\CreateFigure{images/prc_curve_global_VGG_XGB2_test.png}{עקום \ToEn{Precision-Recall}}
\CreateFigure{images/confusion_matrix_VGG_XGB2_test.png}{מטריצת הבלבול}
\clearpage
